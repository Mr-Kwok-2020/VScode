{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from my_netModel.Lenet5 import Lenet5\n",
    "from my_netModel.ResNet import ResNet18\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import lr_scheduler\n",
    "from my_netModel.fun import print_epoching,Timer,music_play,print_epoching_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "        'train': transforms.Compose(\n",
    "            [transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "             transforms.RandomHorizontalFlip(),\n",
    "             transforms.ToTensor(),\n",
    "             transforms.Normalize(mean = [0.4914,0.4822,0.4465],\n",
    "                                  std  = [0.2023,0.1994,0.2010])]  # 图像标准化\n",
    "        ),\n",
    "        'val': transforms.Compose(\n",
    "            [\n",
    "             transforms.Resize((32,32)),   \n",
    "             transforms.ToTensor(),\n",
    "             transforms.Normalize(mean = [0.4914,0.4822,0.4465],\n",
    "                                  std  = [0.2023,0.1994,0.2010])]  # 图像标准化\n",
    "        )\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 32\n",
    "train_dataset = datasets.CIFAR10(root=r\"D:\\data\\cifar10\",train = True,transform=transform['train'])\n",
    "train_loader = DataLoader(train_dataset,batch_size = batch,shuffle=True, num_workers=1)\n",
    "    \n",
    "\n",
    "val_dataset = datasets.CIFAR10(root=r\"D:\\data\\cifar10\",train = False,transform=transform['val'])\n",
    "val_loader = DataLoader(val_dataset,batch_size = batch,shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet18().to(device)\n",
    "\n",
    "# print(net)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=0.003, betas=(0.9, 0.999))\n",
    "# optimizer = torch.optim.Adam(net.parameters(),lr=0.003)\n",
    "scheduler=lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = [] \n",
    "train_acc_list = [] \n",
    "val_epoch_list = []\n",
    "val_loss_list = [] \n",
    "val_acc_list = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_timer  = Timer()\n",
    "train_timer  = Timer()\n",
    "val_timer  = Timer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:23.61%\r"
     ]
    }
   ],
   "source": [
    "epochs = 50 \n",
    "for epoch in range(epochs):\n",
    "        all_timer.start()\n",
    "\n",
    "        net.train()        \n",
    "        batch_acc = 0\n",
    "        batch_loss = 0        \n",
    "        total_num = 0\n",
    "        train_timer.start()\n",
    "\n",
    "        for id,(x,lable) in enumerate(train_loader):\n",
    "                      \n",
    "            x,lable = x.to(device),lable.to(device)\n",
    "            logits = net(x)\n",
    "            loss = criterion(logits,lable)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_acc += sum(torch.argmax(logits,dim = 1)==lable)\n",
    "            batch_loss += loss\n",
    "            total_num  += x.size(0)\n",
    "\n",
    "            print_epoching_per(id,len(train_loader),'train')\n",
    "\n",
    "        train_acc_list.append(batch_acc.item()/total_num)\n",
    "        train_loss_list.append(batch_loss.item()/len(train_loader)) \n",
    "        train_timing = train_timer.stop()\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            net.eval()\n",
    "            batch_acc = 0\n",
    "            total_num = 0\n",
    "            batch_loss = 0\n",
    "            val_timer.start()\n",
    "\n",
    "            for id,(x,lable) in enumerate(val_loader):\n",
    "                \n",
    "                x,lable = x.to(device),lable.to(device)\n",
    "                logits = net(x)\n",
    "                loss = criterion(logits,lable)\n",
    "\n",
    "                batch_loss += loss\n",
    "                batch_acc += sum(torch.argmax(logits,dim = 1)==lable)\n",
    "                total_num += x.size(0)\n",
    "\n",
    "                print_epoching_per(id,len(val_loader),'test ')\n",
    "\n",
    "        \n",
    "        \n",
    "        val_loss_list.append(batch_loss.item()/len(val_loader)) \n",
    "        val_acc_list.append(batch_acc.item()/total_num) \n",
    "        val_epoch_list.append(epoch)\n",
    "        val_timing = val_timer.stop()\n",
    "        all_timing = all_timer.stop()\n",
    "\n",
    "        print('Epoch[{}/{}];time:{:0.2f},{:0.2f},{:0.2f};train_loss:{:0.4f};val_loss:{:0.4f};train_acc:{:0.4f};val_acc:{:0.4f}'.format(\n",
    "            epoch+1, epochs,            \n",
    "            all_timing,train_timing,val_timing,      \n",
    "            train_loss_list[-1],\n",
    "            val_loss_list[-1],                     \n",
    "            train_acc_list[-1],\n",
    "            val_acc_list[-1]\n",
    "        ))  # 打印每个epoch \n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存loss图像\n",
    "plt.plot(range(len(train_loss_list[1:-1])), train_loss_list[1:-1], label=\"train_loss\")\n",
    "plt.plot(range(len(val_loss_list[1:-1])), val_loss_list[1:-1]  , label=\"val_loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(range(len(train_acc_list)), train_acc_list, label=\"train_acc\")\n",
    "plt.plot(range(len(val_acc_list)), val_acc_list, label=\"val_acc\")\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39_usual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
