{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from data_reader import LoadData  # 数据读取\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据目录\n",
    "route = r\"D:\\data\\MNIST\"  # 数据目录\n",
    "result_save_path = r\"C:\\Users\\haokw\\Documents\\GitHub\\VScode\\Gan_dataset_expansion\\model\\CNN_model1\"  # 模型和loss图的保存目录\n",
    "drop_last = False  # 不够一个批次的数据是否舍弃掉，数据量多可以选择True\n",
    "if not os.path.exists(result_save_path):\n",
    "    print(\"dsga\")\n",
    "    os.mkdir(result_save_path)  # 如果没有保存路径的目录文件夹则进行创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练相关的参数\n",
    "lr = 0.002  # 判别器学习率\n",
    "batch_size = 128  # 一个批次的大小\n",
    "num_epoch = 100  # 训练迭代次数\n",
    "output_loss_Interval_ratio = 1  # 间隔多少个epoch打印一次损失\n",
    "test_interval = 1  # 间隔多少个epoch测试一次准确率\n",
    "# 网络结构相关的参数\n",
    "input_number_of_channels = 1  # 输入通道数，RGB为3，GRAY为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分类网络CNN\n",
    "class classification_model(nn.Module):\n",
    "    def __init__(self,output_classes,input_number_of_channels):\n",
    "        \"\"\"\n",
    "        n_classes:类别数\n",
    "        \"\"\"\n",
    "        super(classification_model,self).__init__()\n",
    "        self.structure=nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(input_number_of_channels, 6, kernel_size=5, stride=1, padding=2),  # (m,6,28,28)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),  # (m,6,14,14)\n",
    "\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),  # (6,16,10,10)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),  # (6,16,5,5)\n",
    "\n",
    "            nn.Conv2d(16, output_classes, kernel_size=5, stride=1, padding=0),  # (16,10,1,1)\n",
    "            # nn.Softmax(dim=1)\n",
    "        )   \n",
    "    \n",
    "    def forward(self,x):\n",
    "        out=self.structure(x)\n",
    "        out=out.reshape(out.shape[0],-1)\n",
    "       \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model = classification_model(output_classes=10, input_number_of_channels=input_number_of_channels).cuda()\n",
    "optimer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化训练数据读取器\n",
    "train_dataset = ConcatDataset([LoadData(os.path.join(route, 'train', str(number)), \n",
    "                                        input_number_of_channels=input_number_of_channels) for number in range(0, 10)])  # dataset\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                          shuffle=True, drop_last=drop_last)  # dataloader\n",
    "\n",
    "val_dataset = ConcatDataset([LoadData(os.path.join(route, 'val', str(number)), \n",
    "                                        input_number_of_channels=input_number_of_channels) for number in range(0, 10)])  # dataset\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, drop_last=drop_last)  # dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification_model(\n",
       "  (structure): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(16, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#初始化网络参数函数，用于下一个数字开始训练之前\n",
    "def init_weights(m):\n",
    "    if hasattr(m,'weight'):\n",
    "        nn.init.uniform_(m.weight,-0.1,0.1)\n",
    "\n",
    "# 初始化模型\n",
    "model.apply(init_weights)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classification_model(\n",
       "  (structure): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(16, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化模型\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[0] train:   0%|          | 0/79 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\haokw\\Documents\\GitHub\\VScode\\Gan_dataset_expansion\\使用原始数据训练.ipynb 单元格 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/Gan_dataset_expansion/%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m img, label \u001b[39min\u001b[39;00m tqdm(train_loader, desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch[\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m] train\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/Gan_dataset_expansion/%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(label, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/Gan_dataset_expansion/%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     output \u001b[39m=\u001b[39m model(img\u001b[39m.\u001b[39;49mcuda())  \u001b[39m# 前向传播\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/Gan_dataset_expansion/%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(output, label)  \u001b[39m# 计算loss\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/Gan_dataset_expansion/%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     optimer\u001b[39m.\u001b[39mzero_grad()  \u001b[39m# 梯度清零\u001b[39;00m\n",
      "File \u001b[1;32me:\\conda\\envs\\python39_usual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\haokw\\Documents\\GitHub\\VScode\\Gan_dataset_expansion\\使用原始数据训练.ipynb 单元格 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/Gan_dataset_expansion/%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/Gan_dataset_expansion/%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     out\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructure(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/Gan_dataset_expansion/%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     out\u001b[39m=\u001b[39mout\u001b[39m.\u001b[39mreshape(out\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/Gan_dataset_expansion/%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32me:\\conda\\envs\\python39_usual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\conda\\envs\\python39_usual\\lib\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32me:\\conda\\envs\\python39_usual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\conda\\envs\\python39_usual\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32me:\\conda\\envs\\python39_usual\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "loss_list = []  # 保存每一个epoch的损失值\n",
    "acc_list = []  # 保存每一个epoch的准确率\n",
    "\n",
    "\n",
    "for epoch in range(0, num_epoch+1):  # 迭代num_epoch个epoch\n",
    "    # 训练\n",
    "    model.train()\n",
    "    batch_loss = 0  # 累加每个epoch中全部batch的损失值，最后平均得到每个epoch的损失值\n",
    "    # 每个batch_size的图片\n",
    "    for img, label in tqdm(train_loader, desc=f'Epoch[{epoch}] train'):\n",
    "        label = torch.as_tensor(label, dtype=torch.long).cuda()\n",
    "        output = model(img.cuda())  # 前向传播\n",
    "        loss = criterion(output, label)  # 计算loss\n",
    "        optimer.zero_grad()  # 梯度清零\n",
    "        loss.backward()  # 反向传播\n",
    "        optimer.step()  # 参数更新\n",
    "        batch_loss += loss  # 累加loss\n",
    "   \n",
    "    # 保存损失值为列表,将所有batch累加的损失值除以batch数即该轮epoch的损失值\n",
    "    loss_list.append(batch_loss.item()/len(train_loader))\n",
    "\n",
    "    # 测试\n",
    "    if epoch % test_interval == 0:  # 间隔test_interval个epoch测试一次准确率\n",
    "        model.eval()\n",
    "        batch_acc = 0\n",
    "        # 每个batch_size的图片\n",
    "        for img, label in tqdm(val_loader, desc=f'Epoch[{epoch}] test'):\n",
    "            label = torch.as_tensor(label, dtype=torch.long).cuda()\n",
    "            prediction_output = model(img.cuda())\n",
    "            batch_acc += sum(torch.argmax(prediction_output,dim=1) == label)/len(img)\n",
    "\n",
    "        # 将该轮的测试准确率保存到列表当中\n",
    "        acc_list.append(batch_acc.item()/len(val_loader))\n",
    "\n",
    "    # 打印训练的损失和测试的准确率  #间隔output_loss_Interval_ratio个epoch打印一次损失\n",
    "    if epoch % output_loss_Interval_ratio == 0:\n",
    "        print('Epoch[{}/{}],loss:{:.6f}'.format(\n",
    "            epoch, num_epoch,\n",
    "            batch_loss.item()/len(train_loader)\n",
    "            ))  # 打印每个epoch的损失值\n",
    "\n",
    "    # 如果做了测试，则打印准确率\n",
    "    if epoch % test_interval == 0:\n",
    "        print('Epoch[{}/{}],acc:{:.6f}'.format(\n",
    "            epoch, num_epoch,\n",
    "            acc_list[-1]\n",
    "        ))  # 打印每个epoch的损失值\n",
    "\n",
    "    # 保存loss图像\n",
    "    plt.plot(range(len(loss_list)), loss_list, label=\"loss\")\n",
    "    plt.plot([i*test_interval for i in range(len(acc_list))],\n",
    "             acc_list, label=\"acc\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(result_save_path, 'loss.jpg'))\n",
    "    plt.clf()\n",
    "\n",
    "    # 创建保存模型和loss图的目录\n",
    "    if not os.path.exists(os.path.join(result_save_path)):\n",
    "        os.mkdir(os.path.join(result_save_path))\n",
    "\n",
    "    # 保存模型\n",
    "    torch.save(model, os.path.join(result_save_path, 'last.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39_usual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
