{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from data_reader import LoadData  # 数据读取\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据目录\n",
    "route = r\"D:\\data\\MNIST\"  # 数据目录\n",
    "result_save_path = r\"C:\\Users\\haokw\\Documents\\GitHub\\VScode\\Gan_dataset_expansion\\model\\CNN_model1\"  # 模型和loss图的保存目录\n",
    "drop_last = False  # 不够一个批次的数据是否舍弃掉，数据量多可以选择True\n",
    "if not os.path.exists(result_save_path):\n",
    "    print(\"dsga\")\n",
    "    os.mkdir(result_save_path)  # 如果没有保存路径的目录文件夹则进行创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练相关的参数\n",
    "lr = 0.002  # 判别器学习率\n",
    "batch_size = 128  # 一个批次的大小\n",
    "num_epoch = 100  # 训练迭代次数\n",
    "output_loss_Interval_ratio = 1  # 间隔多少个epoch打印一次损失\n",
    "test_interval = 1  # 间隔多少个epoch测试一次准确率\n",
    "# 网络结构相关的参数\n",
    "input_number_of_channels = 1  # 输入通道数，RGB为3，GRAY为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分类网络CNN\n",
    "class classification_model(nn.Module):\n",
    "    def __init__(self,output_classes,input_number_of_channels):\n",
    "        \"\"\"\n",
    "        n_classes:类别数\n",
    "        \"\"\"\n",
    "        super(classification_model,self).__init__()\n",
    "        self.structure=nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(input_number_of_channels, 6, kernel_size=5, stride=1, padding=2),  # (m,6,28,28)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),  # (m,6,14,14)\n",
    "\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),  # (6,16,10,10)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),  # (6,16,5,5)\n",
    "\n",
    "            nn.Conv2d(16, output_classes, kernel_size=5, stride=1, padding=0),  # (16,10,1,1)\n",
    "            # nn.Softmax(dim=1)\n",
    "        )   \n",
    "    \n",
    "    def forward(self,x):\n",
    "        out=self.structure(x)\n",
    "        out=out.reshape(out.shape[0],-1)\n",
    "       \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model = classification_model(output_classes=10, input_number_of_channels=input_number_of_channels).cuda()\n",
    "optimer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化训练数据读取器\n",
    "train_dataset = ConcatDataset([LoadData(os.path.join(route, 'train', str(number)), \n",
    "                                        input_number_of_channels=input_number_of_channels) for number in range(0, 10)])  # dataset\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                          shuffle=True, drop_last=drop_last)  # dataloader\n",
    "\n",
    "val_dataset = ConcatDataset([LoadData(os.path.join(route, 'val', str(number)), \n",
    "                                        input_number_of_channels=input_number_of_channels) for number in range(0, 10)])  # dataset\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, drop_last=drop_last)  # dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化网络参数函数，用于下一个数字开始训练之前\n",
    "def init_weights(m):\n",
    "    if hasattr(m,'weight'):\n",
    "        nn.init.uniform_(m.weight,-0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[0] train: 100%|██████████| 40/40 [00:01<00:00, 20.24it/s]\n",
      "Epoch[0] test: 100%|██████████| 40/40 [00:02<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/100],loss:0.138184\n",
      "Epoch[0/100],acc:0.938672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch[1] train: 100%|██████████| 40/40 [00:01<00:00, 20.01it/s]\n",
      "Epoch[1] test:   0%|          | 0/40 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\haokw\\Documents\\GitHub\\VScode\\Gan_dataset_expansion\\使用原始数据训练.ipynb 单元格 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/Gan_dataset_expansion/%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m batch_acc \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/Gan_dataset_expansion/%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# 每个batch_size的图片\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/Gan_dataset_expansion/%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mfor\u001b[39;00m img, label \u001b[39min\u001b[39;00m tqdm(val_loader, desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch[\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m] test\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/Gan_dataset_expansion/%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(label, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/Gan_dataset_expansion/%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E8%AE%AD%E7%BB%83.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     prediction_output \u001b[39m=\u001b[39m model(img\u001b[39m.\u001b[39mcuda())\n",
      "File \u001b[1;32me:\\conda\\envs\\python39_usual\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32me:\\conda\\envs\\python39_usual\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32me:\\conda\\envs\\python39_usual\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32me:\\conda\\envs\\python39_usual\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32me:\\conda\\envs\\python39_usual\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32me:\\conda\\envs\\python39_usual\\lib\\site-packages\\torch\\utils\\data\\dataset.py:240\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     sample_idx \u001b[39m=\u001b[39m idx \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcumulative_sizes[dataset_idx \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m--> 240\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatasets[dataset_idx][sample_idx]\n",
      "File \u001b[1;32mc:\\Users\\haokw\\Documents\\GitHub\\VScode\\Gan_dataset_expansion\\data_reader.py:28\u001b[0m, in \u001b[0;36mLoadData.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     26\u001b[0m img_path, label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs_info[index]\n\u001b[0;32m     27\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(img_path)\n\u001b[1;32m---> 28\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mconvert(\u001b[39m'\u001b[39;49m\u001b[39mRGB\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     29\u001b[0m img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtf(img)\n\u001b[0;32m     30\u001b[0m \u001b[39mreturn\u001b[39;00m img,\u001b[39mfloat\u001b[39m(label)\n",
      "File \u001b[1;32me:\\conda\\envs\\python39_usual\\lib\\site-packages\\PIL\\Image.py:937\u001b[0m, in \u001b[0;36mImage.convert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert\u001b[39m(\n\u001b[0;32m    890\u001b[0m     \u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, matrix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dither\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, palette\u001b[39m=\u001b[39mPalette\u001b[39m.\u001b[39mWEB, colors\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m\n\u001b[0;32m    891\u001b[0m ):\n\u001b[0;32m    892\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[39m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[39m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[39m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m    939\u001b[0m     has_transparency \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtransparency\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    940\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mode \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mP\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    941\u001b[0m         \u001b[39m# determine default mode\u001b[39;00m\n",
      "File \u001b[1;32me:\\conda\\envs\\python39_usual\\lib\\site-packages\\PIL\\ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(msg)\n\u001b[0;32m    268\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[1;32m--> 269\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[0;32m    270\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    271\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "loss_list = []  # 保存每一个epoch的损失值\n",
    "acc_list = []  # 保存每一个epoch的准确率\n",
    "\n",
    "\n",
    "for epoch in range(0, num_epoch+1):  # 迭代num_epoch个epoch\n",
    "    # 训练\n",
    "    model.train()\n",
    "    batch_loss = 0  # 累加每个epoch中全部batch的损失值，最后平均得到每个epoch的损失值\n",
    "    # 每个batch_size的图片\n",
    "    for img, label in tqdm(train_loader, desc=f'Epoch[{epoch}] train'):\n",
    "        label = torch.as_tensor(label, dtype=torch.long).cuda()\n",
    "        output = model(img.cuda())  # 前向传播\n",
    "        loss = criterion(output, label)  # 计算loss\n",
    "        optimer.zero_grad()  # 梯度清零\n",
    "        loss.backward()  # 反向传播\n",
    "        optimer.step()  # 参数更新\n",
    "        batch_loss += loss  # 累加loss\n",
    "   \n",
    "    # 保存损失值为列表,将所有batch累加的损失值除以batch数即该轮epoch的损失值\n",
    "    loss_list.append(batch_loss.item()/len(train_loader))\n",
    "\n",
    "    # 测试\n",
    "    if epoch % test_interval == 0:  # 间隔test_interval个epoch测试一次准确率\n",
    "        model.eval()\n",
    "        batch_acc = 0\n",
    "        # 每个batch_size的图片\n",
    "        for img, label in tqdm(val_loader, desc=f'Epoch[{epoch}] test'):\n",
    "            label = torch.as_tensor(label, dtype=torch.long).cuda()\n",
    "            prediction_output = model(img.cuda())\n",
    "            batch_acc += sum(torch.argmax(prediction_output,dim=1) == label)/len(img)\n",
    "\n",
    "        # 将该轮的测试准确率保存到列表当中\n",
    "        acc_list.append(batch_acc.item()/len(val_loader))\n",
    "\n",
    "    # 打印训练的损失和测试的准确率  #间隔output_loss_Interval_ratio个epoch打印一次损失\n",
    "    if epoch % output_loss_Interval_ratio == 0:\n",
    "        print('Epoch[{}/{}],loss:{:.6f}'.format(\n",
    "            epoch, num_epoch,\n",
    "            batch_loss.item()/len(train_loader)\n",
    "            ))  # 打印每个epoch的损失值\n",
    "\n",
    "    # 如果做了测试，则打印准确率\n",
    "    if epoch % test_interval == 0:\n",
    "        print('Epoch[{}/{}],acc:{:.6f}'.format(\n",
    "            epoch, num_epoch,\n",
    "            acc_list[-1]\n",
    "        ))  # 打印每个epoch的损失值\n",
    "\n",
    "    # 保存loss图像\n",
    "    plt.plot(range(len(loss_list)), loss_list, label=\"loss\")\n",
    "    plt.plot([i*test_interval for i in range(len(acc_list))],\n",
    "             acc_list, label=\"acc\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(result_save_path, 'loss.jpg'))\n",
    "    plt.clf()\n",
    "\n",
    "    # 创建保存模型和loss图的目录\n",
    "    if not os.path.exists(os.path.join(result_save_path)):\n",
    "        os.mkdir(os.path.join(result_save_path))\n",
    "\n",
    "    # 保存模型\n",
    "    torch.save(model, os.path.join(result_save_path, 'last.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39_usual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
