{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from data_reader import LoadData  # 数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据目录\n",
    "route = r\"D:\\data\\MNIST\"  # 数据目录\n",
    "result_save_path = r\"C:\\Users\\haokw\\Documents\\GitHub\\VScode\\Gan_dataset_expansion\\model\\CNN_model1\"  # 模型和loss图的保存目录\n",
    "drop_last = False  # 不够一个批次的数据是否舍弃掉，数据量多可以选择True\n",
    "if not os.path.exists(result_save_path):\n",
    "    print(\"dsga\")\n",
    "    os.mkdir(result_save_path)  # 如果没有保存路径的目录文件夹则进行创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练相关的参数\n",
    "lr_d = 0.002  # 判别器学习率\n",
    "lr_g = 0.002  # 生成器学习率\n",
    "batch_size = 100  # 一个批次的大小\n",
    "num_epoch = 300  # 训练迭代次数\n",
    "output_loss_Interval_ratio = 1  # 间隔多少个epoch打印一次损失\n",
    "save_model_Interval_ratio = 50  # 间隔多少个epoch保存一次训练过程中的fake图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络结构相关的参数\n",
    "g_d_nc = 1  # d的输入通道和g的输出通道，RGB为3，GRAY为1\n",
    "g_input = 100  # g的输入噪声点个数\n",
    "ndf=64 #判别网络卷积核个数的倍数\n",
    "ngf=64 #生成网络卷积核个数的倍数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成器网络G\n",
    "class generator(nn.Module):\n",
    "    def __init__(self,noise_number,number_of_channels):\n",
    "        \"\"\"\n",
    "        noise_number:输入噪声点个数\n",
    "        number_of_channels:生成图像通道数\n",
    "        \"\"\"\n",
    "        super(generator,self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            # 输入大小  batch x noise_number x 1 * 1\n",
    "            nn.ConvTranspose2d(noise_number , ngf * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # 输入大小 batch x (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # 输入大小 batch x (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf , 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf ),\n",
    "            nn.ReLU(True),\n",
    "            # 输入大小 batch x (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf   , number_of_channels, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # 输出大小 batch x (nc) x 64 x 64\n",
    "       )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.gen(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#判别器网络D\n",
    "class discriminator(nn.Module):\n",
    "    def __init__(self,number_of_channels):\n",
    "        \"\"\"\n",
    "        number_of_channels:输入图像通道数\n",
    "        \"\"\"\n",
    "        super(discriminator, self).__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "            # 输入大小 batch x g_d_nc x 64*64\n",
    "            nn.Conv2d(number_of_channels, ndf  , 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf ),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 输入大小 batch x ndf x 32*32\n",
    "            nn.Conv2d(ndf , ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 输入大小 batch x (ndf*2) x 16*16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 输入大小 batch x (ndf*8) x 4*4\n",
    "            nn.Conv2d(ndf * 4 , 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "            # 输出大小 batch x 1 x 1*1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.dis(x).view(x.shape[0],-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化生成器和判别器\n",
    "d = discriminator(number_of_channels=g_d_nc).cuda()\n",
    "g = generator(noise_number=g_input,\n",
    "              number_of_channels=g_d_nc).cuda()  # 模型迁移至GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义loss的度量方式\n",
    "criterion = nn.BCELoss()  # 单目标二分类交叉熵函数\n",
    "# 定义 优化函数 学习率\n",
    "d_optimizer = torch.optim.Adam(\n",
    "    d.parameters(), lr=lr_d, betas=(0.5, 0.999))  # Adam优化器\n",
    "g_optimizer = torch.optim.Adam(g.parameters(), lr=lr_g, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#初始化网络参数函数，用于下一个数字开始训练之前\n",
    "def init_weights(m):\n",
    "    if hasattr(m,'weight'):\n",
    "        nn.init.uniform_(m.weight,-0.1,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|          | 0/301 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "number:0 Epoch[0/300],d_loss:1.045397,g_loss:1.869781 D real: 0.699753,D fake: 0.468833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:   0%|          | 1/301 [00:13<1:09:52, 13.98s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "for number in range(0, 10):  # 0-9每一个数字单独训练\n",
    "    # 初始化网络每一层的参数\n",
    "    d.apply(init_weights)\n",
    "    g.apply(init_weights)\n",
    "\n",
    "    # #恢复训练\n",
    "    # g=torch.load(os.path.join(result_save_path,str(number),str(number)+'_g__last.pth'))\n",
    "    # d=torch.load(os.path.join(result_save_path,str(number),str(number)+'_d__last.pth'))\n",
    "\n",
    "    # 初始化训练数据读取器\n",
    "    train_dataset = LoadData(os.path.join(route, 'train', str(\n",
    "        number)), input_number_of_channels=g_d_nc)  # dataset\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size,\n",
    "                              shuffle=True, drop_last=drop_last)  # dataloader\n",
    "\n",
    "    loss_list_g, loss_list_d = [], []  # 保存每一个epoch的损失值\n",
    "    for epoch in tqdm(range(0, num_epoch+1), desc='epoch'):  # 迭代num_epoch个epoch\n",
    "        batch_d_loss, batch_g_loss = 0, 0  # 累加每个epoch中全部batch的损失值，最后平均得到每个epoch的损失值\n",
    "        for img, label in train_loader:  # 每个batch_size的图片\n",
    "            img_number = len(img)  # 该批次有多少张图片\n",
    "            real_img = img.cuda()  # 将tensor放入cuda中\n",
    "            real_label = torch.ones(img_number).cuda()  # 定义真实的图片label为1\n",
    "            fake_label = torch.zeros(img_number).cuda()  # 定义假的图片的label为0\n",
    "\n",
    "            # ==================训练判别器==================\n",
    "            # 分为两部分：1、真的图像判别为真；2、假的图像判别为假\n",
    "            # 计算真实图片的损失\n",
    "            real_out = d(real_img)  # 将真实图片放入判别器中\n",
    "            real_label = real_label.reshape([-1, 1])  # shape (n) -> (n,1)\n",
    "            d_loss_real = criterion(real_out, real_label)  # 得到真实图片的loss\n",
    "            real_scores = real_out  # 得到真实图片的判别值，输出的值越接近1越好\n",
    "            # 计算假的图片的损失\n",
    "            z = torch.randn(img_number, g_input, 1, 1).cuda()  # 随机生成一些噪声\n",
    "            # 随机噪声放入生成网络中，生成一张假的图片。 # 避免梯度传到G，因为G不用更新, detach分离\n",
    "            fake_img = g(z).detach()\n",
    "            fake_out = d(fake_img)  # 判别器判断假的图片，\n",
    "            fake_label = fake_label.reshape([-1, 1])  # shape (n) -> (n,1)\n",
    "            d_loss_fake = criterion(fake_out, fake_label)  # 得到假的图片的loss\n",
    "            fake_scores = fake_out  # 得到假图片的判别值，对于判别器来说，假图片的损失越接近0越好\n",
    "            # 合计判别器的总损失\n",
    "            d_loss = d_loss_real + d_loss_fake  # 损失包括判真损失和判假损失\n",
    "            # 反向传播，参数更新\n",
    "            d_optimizer.zero_grad()  # 在反向传播之前，先将梯度归0\n",
    "            d_loss.backward()  # 将误差反向传播\n",
    "            d_optimizer.step()  # 更新参数\n",
    "\n",
    "            # ==================训练生成器==================\n",
    "            # 原理：目的是希望生成的假的图片被判别器判断为真的图片，\n",
    "            # 在此过程中，将判别器固定，将假的图片传入判别器的结果与真实的label对应，\n",
    "            # 反向传播更新的参数是生成网络里面的参数，\n",
    "            # 这样可以通过更新生成网络里面的参数，来训练网络，使得生成的图片让判别器以为是真的\n",
    "            # 这样就达到了对抗的目的\n",
    "            # 计算假的图片的损失\n",
    "            z = torch.randn(img_number, g_input, 1, 1).cuda()  # 得到随机噪声\n",
    "            fake_img = g(z)  # 随机噪声输入到生成器中，得到一副假的图片\n",
    "            output = d(fake_img)  # 经过判别器得到的结果\n",
    "            g_loss = criterion(output, real_label)  # 得到的假的图片与真实的图片的label的loss\n",
    "            # 反向传播，参数更新\n",
    "            g_optimizer.zero_grad()  # 梯度归0\n",
    "            g_loss.backward()  # 进行反向传播\n",
    "            g_optimizer.step()  # .step()一般用在反向传播后面,用于更新生成网络的参数\n",
    "\n",
    "            # ==================累加总损失值，后面进行损失值可视化==================\n",
    "            batch_d_loss += d_loss  # 累加每一个batch的损失值\n",
    "            batch_g_loss += g_loss  # 累加每一个batch的损失值\n",
    "\n",
    "        # # 调整学习率,当判别器损失足够小的时候，大幅度降低d的学习率，防止d过于完美，导致g无法训练(增加epoch次数可以开启)\n",
    "        # if d_loss < 0.5:\n",
    "        #     for i in d_optimizer.param_groups:\n",
    "        #         i['lr']=lr_d/10\n",
    "\n",
    "        # 将该轮的损失函数值保存到列表当中\n",
    "        # 保存g损失值为列表,将所有batch累加的损失值除以batch数即该轮epoch的损失值\n",
    "        loss_list_g.append(batch_g_loss.item()/len(train_loader))\n",
    "        loss_list_d.append(batch_d_loss.item()/len(train_loader))  # 保存d损失值为列表\n",
    "\n",
    "        # 打印中间的损失  #间隔output_loss_Interval_ratio个epoch打印一次损失\n",
    "        if epoch % output_loss_Interval_ratio == 0:\n",
    "            print('\\nnumber:{} Epoch[{}/{}],d_loss:{:.6f},g_loss:{:.6f} '\n",
    "                  'D real: {:.6f},D fake: {:.6f}'.format(\n",
    "                      number, epoch, num_epoch,\n",
    "                      batch_d_loss.item()/len(train_loader),\n",
    "                      batch_g_loss.item()/len(train_loader),\n",
    "                      real_scores.data.mean(),\n",
    "                      fake_scores.data.mean()\n",
    "                  ))  # 打印每个epoch的d和g损失值（越小越好）和d的判别值（real越接近1越好，fake越接近0越好）\n",
    "\n",
    "        # 创建保存模型和生成fake样本以及loss图的目录\n",
    "        if not os.path.exists(os.path.join(result_save_path, str(number))):\n",
    "            os.mkdir(os.path.join(result_save_path, str(number)))\n",
    "\n",
    "        # 保存生成的fake图片，间隔save_model_Interval_ratio个epoch保存一次\n",
    "        if epoch % save_model_Interval_ratio == 0:\n",
    "            save_image(fake_img, os.path.join(result_save_path, str(number),\n",
    "                                              str(number)+'_fake_epoch'+str(epoch)+'.jpg'))\n",
    "\n",
    "        # 保存模型,for分别保存g和d，每个epoch都保存一次last.pth\n",
    "        for g_or_d, g_d_name in zip([g, d], ['_g_', '_d_']):\n",
    "            torch.save(g_or_d, os.path.join(result_save_path,\n",
    "                       str(number), str(number)+g_d_name+'last.pth'))\n",
    "\n",
    "        # 保存loss图像\n",
    "        plt.plot(range(len(loss_list_g)), loss_list_g, label=\"g_loss\")\n",
    "        plt.plot(range(len(loss_list_d)), loss_list_d, label=\"d_loss\")\n",
    "        plt.xlabel(\"epoch\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(result_save_path, str(number), 'loss.jpg'))\n",
    "        plt.clf()\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39_usual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
