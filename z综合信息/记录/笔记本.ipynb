{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "EnvironmentNameNotFound: Could not find conda environment: py\n",
      "You can list all discoverable environments with `conda info --envs`.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda activate py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '交叉熵' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\haokw\\Documents\\GitHub\\VScode\\综合信息\\记录\\笔记本.ipynb 单元格 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/%E7%BB%BC%E5%90%88%E4%BF%A1%E6%81%AF/%E8%AE%B0%E5%BD%95/%E7%AC%94%E8%AE%B0%E6%9C%AC.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m 交叉熵\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/%E7%BB%BC%E5%90%88%E4%BF%A1%E6%81%AF/%E8%AE%B0%E5%BD%95/%E7%AC%94%E8%AE%B0%E6%9C%AC.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/haokw/Documents/GitHub/VScode/%E7%BB%BC%E5%90%88%E4%BF%A1%E6%81%AF/%E8%AE%B0%E5%BD%95/%E7%AC%94%E8%AE%B0%E6%9C%AC.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name '交叉熵' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "交叉熵\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.distributions import Categorical, kl\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Cross entropy loss\n",
    "p = [1, 2, 3, 4]\n",
    "q = [1] # [0, 1, 0, 0] = torch.nn.functional.one_hot(torch.tensor(q), len(p))\n",
    "\n",
    "celoss = -p[q[0]] + np.log(sum([np.exp(i) for i in p]))\n",
    "print (f\"Cross Entropy Loss: {celoss}\")\n",
    "\n",
    "loss = CrossEntropyLoss()\n",
    "tensor_p = torch.FloatTensor(p).unsqueeze(0)\n",
    "tensor_q = torch.tensor(q)\n",
    "output = loss(tensor_p, tensor_q)\n",
    "print (f\"Torch Cross Entropy Loss: {output.item()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(label)\n",
    "summ = 0\n",
    "# for i in range(len(label)):\n",
    "#     summ += math.log1p(output[i][label[i]])\n",
    "#     print(output[i][label[i]])\n",
    "# print(summ)\n",
    "p = [1, 2, 3, 4]\n",
    "q = [1] # [0, 1, 0, 0] = torch.nn.functional.one_hot(torch.tensor(q), len(p))\n",
    "\n",
    "celoss = -p[q[0]] + np.log(sum([np.exp(i) for i in p]))\n",
    "for i in range(len(label)):\n",
    "    summ += -output[i][label[i]] + math.log(sum([math.exp(output[i][j]) for j in range(10)]))\n",
    "    # print(math.log(sum([(output[i][j]) for j in range(10)])))\n",
    "print(summ)\n",
    "\n",
    "\n",
    "print(summ/5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_rows\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "def compose_gif():\n",
    "    # 图片地址\n",
    "    data_dir = r\"E:\\demo_study\\jupyter\\Jupyter_notebook\\Handwritten-numeral-generation-based-on-GAN\\images\"\n",
    "    data_dir = pathlib.Path(data_dir)\n",
    "    paths    = list(data_dir.glob('*'))\n",
    "    k = 0\n",
    "    gif_images = []\n",
    "    for path in paths:\n",
    "#         print(path)\n",
    "        k = k + 1\n",
    "        if k%2 == 1:\n",
    "            gif_images.append(imageio.imread(path))\n",
    "    imageio.mimsave(\"test.gif\",gif_images,fps=4)\n",
    "    \n",
    "compose_gif()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images1,_), (_,_) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(train_images1,_), (_,_) = tf.keras.datasets.mnist.load_data()\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "\n",
    "pyplot.imshow(train_images1[0].reshape((28, 28)), cmap=\"gray\")\n",
    "print(train_images1[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rgnet)\n",
    "\n",
    "print(rgnet) 会打印模型的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()\n",
    "使用 info() 函数：\n",
    "info() \n",
    "函数会显示列名、非空值的数量以及每一列的数据类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()\n",
    "\n",
    "string_col = df_train.select_dtypes(include=\"object\").columns\n",
    "print(len(string_col))\n",
    "\n",
    "df_train[string_col]=df_train[string_col].astype(\"string\")\n",
    "\n",
    "df_train.info()\n",
    "\n",
    "string_col=df_train.select_dtypes(\"string\").columns.to_list()\n",
    "\n",
    "\n",
    "num_col=df_train.columns.to_list()\n",
    "#print(num_col)\n",
    "for col in string_col:\n",
    "    num_col.remove(col)\n",
    "\n",
    "# 计算相关性矩阵\n",
    "correlation_matrix = df_train[num_col].corr()\n",
    "\n",
    "# 绘制相关性矩阵的热图\n",
    "plt.figure(figsize=(100, 100))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Plot of the Heart Failure Prediction\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 选择数值列\n",
    "num_col = train_data.select_dtypes(include=['int', 'float64']).columns\n",
    "\n",
    "# 计算相关性矩阵\n",
    "correlation_matrix = train_data[num_col].corr()\n",
    "# 绘制相关性矩阵的热图\n",
    "plt.figure(figsize=(13, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Plot of the Heart Failure Prediction\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 假设 df_train 包含你的数据\n",
    "# 选择要绘制的列，这些列应该是数值型的\n",
    "# 画出散布矩阵（Scatter Matrix）\n",
    "subset = df_train[num_col]\n",
    "sns.pairplot(subset)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "在计算相关性矩阵时，DataFrame 中包含了非数值类型的列：\n",
    "    要解决这个问题，你可以采取以下步骤：\n",
    "        将非数值类型的列转换为数值类型，以便能够计算相关性.\n",
    "        独热编码（One-Hot Encoding）将其转换为数值表示。\n",
    "        标签编码解决上面的问题，你可以将分类变量转换为整数值\n",
    "        计算相关性矩阵时舍弃非数值的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "我们可以将暂退法应用于每个隐藏层的输出（在激活函数之后）， \n",
    "并且可以为每一层分别设置暂退概率： 常见的技巧是在靠近输入层\n",
    "的地方设置较低的暂退概率。 下面的模型将第一个和第二个隐藏层\n",
    "的暂退概率分别设置为0.2和0.5， 并且暂退法只在训练期间有效。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数的目的是将Fashion-MNIST数据集的数值标签转换为相应的文本标签。\n",
    "def get_fashion_mnist_labels(labels):  #@save\n",
    "    \"\"\"返回Fashion-MNIST数据集的文本标签\"\"\"\n",
    "    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
    "                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
    "    return [text_labels[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):  #@save\n",
    "    \"\"\"绘制图像列表\"\"\"\n",
    "    figsize = (num_cols * scale, num_rows * scale)\n",
    "    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        if torch.is_tensor(img):\n",
    "            # 图片张量\n",
    "            ax.imshow(img.numpy())\n",
    "        else:\n",
    "            # PIL图片\n",
    "            ax.imshow(img)\n",
    "        ax.axes.get_xaxis().set_visible(False)\n",
    "        ax.axes.get_yaxis().set_visible(False)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "    return axes\n",
    "\n",
    "X, y = next(iter(data.DataLoader(mnist_train, batch_size=10)))\n",
    "show_images(X.reshape(10, 28, 28), 2, 5, titles=get_fashion_mnist_labels(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置显示选项的有用代码行，这样我们就可以看到pd数据帧中的所有列\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "如果 y 是一个大小为 10 的一维数组，y.reshape((-1, 1)) 将会把它变成一个包含 10 行 1 列的二维数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 创建DataFrame\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 查看前几行数据\n",
    "print(df.head())\n",
    "\n",
    "# 查看DataFrame的基本统计信息\n",
    "print(df.describe())\n",
    "\n",
    "# 获取DataFrame的列名\n",
    "print(df.columns)\n",
    "\n",
    "# 获取DataFrame的形状（行数和列数）\n",
    "print(df.shape)\n",
    "\n",
    "# 选择单列\n",
    "print(df['Name'])\n",
    "\n",
    "# 选择多列\n",
    "print(df[['Name', 'Age']])\n",
    "\n",
    "# 根据条件选择行\n",
    "print(df[df['Age'] > 30])\n",
    "\n",
    "# 添加新列\n",
    "df['City'] = ['New York', 'San Francisco', 'Los Angeles']\n",
    "\n",
    "# 删除列\n",
    "df.drop('City', axis=1, inplace=True)\n",
    "\n",
    "# 使用loc根据标签索引行和列\n",
    "print(df.loc[0])\n",
    "print(df.loc[:, 'Name'])\n",
    "print(df.loc[0:1, 'Name':'Age'])\n",
    "\n",
    "# 使用iloc根据位置索引行和列\n",
    "print(df.iloc[0])\n",
    "print(df.iloc[:, 0])\n",
    "print(df.iloc[0:2, 0:2])\n",
    "\n",
    "# 按列排序\n",
    "print(df.sort_values(by='Age', ascending=False))\n",
    "\n",
    "# 恢复索引\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 应用函数到列\n",
    "df['Age'] = df['Age'].apply(lambda x: x + 1)\n",
    "\n",
    "# 使用条件进行更新\n",
    "df['Age'] = df['Age'].apply(lambda x: x if x > 18 else 'Underage')\n",
    "\n",
    "# 使用groupby进行分组和聚合操作\n",
    "print(df.groupby('City')['Age'].mean())\n",
    "\n",
    "# 检查缺失值\n",
    "print(df.isnull())\n",
    "\n",
    "# 填充缺失值\n",
    "# df.fillna(value, inplace=True)\n",
    "\n",
    "# 删除包含缺失值的行\n",
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置显示选项的有用代码行，这样我们就可以看到pd数据帧中的所有列\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取四个数据集的列名字\n",
    "train_cols = list(train.columns)\n",
    "test_cols = list(test.columns)\n",
    "train_orig_cols = list(train_orig.columns)\n",
    "\n",
    "# 构成一个29*4的数组\n",
    "all_cols = [train_cols, test_cols, train_orig_cols]\n",
    "col_lengths = [len(cols) for cols in all_cols]\n",
    "max_col_length = max(col_lengths)\n",
    "\n",
    "# 填充空白列名字，使所有子列表长度相等\n",
    "for cols in all_cols:\n",
    "    while len(cols) < max_col_length:\n",
    "        cols.append(\"\")\n",
    "\n",
    "# 将四个列表合并成一个二维数组\n",
    "cols_array = np.array(all_cols).T\n",
    "\n",
    "# 打印为表格形式，居中显示\n",
    "for row in cols_array:\n",
    "    print(\"\\t\".join(f\"{col:^{max_col_length}}\" for col in row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "处理分类变量:分类变量/特征是任何特征类型，可分为两种主要类型：\n",
    "    对于不是基于树的机器学习算法，最好的方法是使用One-Hot编码\n",
    "        One-Hot-Encoding的优点是结果是二进制而不是序数，并且所有内容都位于正交向量空间中。\n",
    "        缺点是，对于高基数，特征空间真的会很快爆炸，你开始与维数灾难作斗争。在这些情况下，我通常使用one-hot编码，然后使用PCA进行降维。我发现one-hot加上PCA的明智组合很少能被其他编码方案击败。PCA发现线性重叠，因此将自然倾向于将相似特征分组为同一特征\n",
    "    对于基于树的机器学习算法，最好的方法是使用标签编码\n",
    "        LabelEncoder可以将[dog，cat，dog，mouse，cat]转换为[1，2，1，3，2]，但随后强加的序数意味着dog和mouse的平均值是cat。仍然有一些算法，如决策树和随机森林，可以很好地处理分类变量，LabelEncoder可以用来使用更少的磁盘空间存储值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "选择解释器的时候，如果无法选择conda创建的其他虚拟环境，进入设置ctrl+shift+p,输入 Clear Workspace Interpreter Setting \n",
    "\n",
    "clear \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "一些常用的Conda指令，用于管理和操作Conda环境和软件包：\n",
    "\n",
    "    创建一个新的Conda环境：\n",
    "\n",
    "    lua\n",
    "    Copy code\n",
    "    conda create --name myenv\n",
    "    创建一个新的Conda环境并指定Python版本：\n",
    "\n",
    "    lua\n",
    "    Copy code\n",
    "    conda create --name myenv python=3.8\n",
    "    激活一个Conda环境：\n",
    "\n",
    "    Copy code\n",
    "    conda activate myenv\n",
    "    列出所有已创建的Conda环境：\n",
    "\n",
    "    bash\n",
    "    Copy code\n",
    "    conda env list\n",
    "    安装软件包到当前活动的环境：\n",
    "\n",
    "    Copy code\n",
    "    conda install package_name\n",
    "    安装特定版本的软件包：\n",
    "\n",
    "    Copy code\n",
    "    conda install package_name=1.2.3\n",
    "    更新已安装的软件包：\n",
    "\n",
    "    sql\n",
    "    Copy code\n",
    "    conda update package_name\n",
    "    卸载软件包：\n",
    "\n",
    "    arduino\n",
    "    Copy code\n",
    "    conda remove package_name\n",
    "    列出当前环境中已安装的软件包：\n",
    "\n",
    "    Copy code\n",
    "    conda list\n",
    "    列出所有可用的Conda环境：\n",
    "\n",
    "    css\n",
    "    Copy code\n",
    "    conda info --envs\n",
    "    导出当前环境的软件包列表到一个文件：\n",
    "\n",
    "    arduino\n",
    "    Copy code\n",
    "    conda list --export > environment.yml\n",
    "    使用环境文件创建一个新的Conda环境：\n",
    "\n",
    "    bash\n",
    "    Copy code\n",
    "    \n",
    "    导出当前环境的所有内容（包括软件包和环境配置）到一个压缩文件：\n",
    "\n",
    "    bash\n",
    "    Copy code\n",
    "    conda env export --file environment.yml\n",
    "    删除一个Conda环境：\n",
    "\n",
    "    lua\n",
    "    Copy code\n",
    "    conda env remove --name myenv\n",
    "    查找可用的Conda软件包：\n",
    "\n",
    "    sql\n",
    "    Copy code\n",
    "    conda search package_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda-forge是一个社区维护的Conda通道，用于提供大量的开源软件包。它是一个独立于Anaconda和Miniconda的第三方通道，致力于提供更多的软件包和更新，以满足各种需求。\n",
    "\n",
    "一些主要的特点和用途包括：\n",
    "\n",
    "更多软件包： conda-forge通道包含了许多不包含在默认Anaconda仓库中的软件包。这意味着你可以更容易地找到和安装各种开源软件和工具。\n",
    "\n",
    "最新版本： conda-forge通道通常会更快地提供最新版本的软件包，以便用户能够访问最新的功能和改进。\n",
    "\n",
    "社区驱动： conda-forge是一个社区驱动的项目，由社区成员维护和更新。这使得更多的软件包能够进入通道并得到支持。\n",
    "\n",
    "要使用conda-forge通道，你可以按照以下步骤操作：\n",
    "\n",
    "添加conda-forge通道： 在使用Conda之前，你可以将conda-forge通道添加到Conda配置中，这样你就可以从该通道安装软件包。使用以下命令添加通道：\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "conda config --add channels conda-forge\n",
    "这将在你的Conda配置中添加conda-forge通道。\n",
    "\n",
    "安装软件包： 一旦添加了conda-forge通道，你可以使用conda install命令从通道中安装软件包，如之前提到的conda install -c conda-forge package-name。\n",
    "\n",
    "升级软件包： 你还可以使用conda update命令从conda-forge通道中升级已安装的软件包，如conda update -c conda-forge package-name。\n",
    "\n",
    "请注意，使用conda-forge通道可能会增加一些风险，因为它包含的软件包可能不经过官方Anaconda的严格测试。因此，在使用新软件包之前，建议仔细阅读文档并测试其兼容性。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39_usual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
